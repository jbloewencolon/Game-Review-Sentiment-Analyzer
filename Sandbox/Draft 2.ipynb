{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import randint, uniform\n",
    "from xgboost import XGBClassifier\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('D:/Git/phase_4/Hades_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 457440 entries, 0 to 457439\n",
      "Data columns (total 27 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   Unnamed: 0                      457440 non-null  int64  \n",
      " 1   query_summary                   0 non-null       float64\n",
      " 2   cursors                         0 non-null       float64\n",
      " 3   recommendationid                228720 non-null  float64\n",
      " 4   language                        228720 non-null  object \n",
      " 5   review                          228017 non-null  object \n",
      " 6   timestamp_created               228720 non-null  float64\n",
      " 7   timestamp_updated               228720 non-null  float64\n",
      " 8   voted_up                        228720 non-null  object \n",
      " 9   votes_up                        228720 non-null  float64\n",
      " 10  votes_funny                     228720 non-null  float64\n",
      " 11  weighted_vote_score             228720 non-null  float64\n",
      " 12  comment_count                   228720 non-null  float64\n",
      " 13  steam_purchase                  228720 non-null  object \n",
      " 14  received_for_free               228720 non-null  object \n",
      " 15  written_during_early_access     228720 non-null  object \n",
      " 16  hidden_in_steam_china           228720 non-null  object \n",
      " 17  steam_china_location            0 non-null       float64\n",
      " 18  author.steamid                  228720 non-null  float64\n",
      " 19  author.num_games_owned          228720 non-null  float64\n",
      " 20  author.num_reviews              228720 non-null  float64\n",
      " 21  author.playtime_forever         228720 non-null  float64\n",
      " 22  author.playtime_last_two_weeks  228720 non-null  float64\n",
      " 23  author.playtime_at_review       228720 non-null  float64\n",
      " 24  author.last_played              228720 non-null  float64\n",
      " 25  timestamp_dev_responded         19 non-null      float64\n",
      " 26  developer_response              19 non-null      object \n",
      "dtypes: float64(18), int64(1), object(8)\n",
      "memory usage: 94.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Nulls\n",
    "df = df.dropna(subset=['review'])\n",
    "\n",
    "#Keep only English reviews\n",
    "df = df[df['language'] == 'english']\n",
    "\n",
    "# Drop Unnecessary Columns\n",
    "df = df.drop(df.columns[[0, 1, 2, 3, 4, 6, 7, 16, 17, 18]], axis=1)\n",
    "\n",
    "# Create a mask where each review has more than 5 words and at least one alphabetic character\n",
    "mask = df['review'].apply(lambda x: len(re.findall(r'\\b\\w+\\b', str(x))) > 5 and bool(re.search('[a-zA-Z]', str(x))))\n",
    "\n",
    "# Apply the mask to the DataFrame to filter out review\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 76744 entries, 228720 to 457437\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   review                          76744 non-null  object \n",
      " 1   voted_up                        76744 non-null  object \n",
      " 2   votes_up                        76744 non-null  float64\n",
      " 3   votes_funny                     76744 non-null  float64\n",
      " 4   weighted_vote_score             76744 non-null  float64\n",
      " 5   comment_count                   76744 non-null  float64\n",
      " 6   steam_purchase                  76744 non-null  object \n",
      " 7   received_for_free               76744 non-null  object \n",
      " 8   written_during_early_access     76744 non-null  object \n",
      " 9   author.num_games_owned          76744 non-null  float64\n",
      " 10  author.num_reviews              76744 non-null  float64\n",
      " 11  author.playtime_forever         76744 non-null  float64\n",
      " 12  author.playtime_last_two_weeks  76744 non-null  float64\n",
      " 13  author.playtime_at_review       76744 non-null  float64\n",
      " 14  author.last_played              76744 non-null  float64\n",
      " 15  timestamp_dev_responded         12 non-null     float64\n",
      " 16  developer_response              12 non-null     object \n",
      "dtypes: float64(11), object(6)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>weighted_vote_score</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>steam_purchase</th>\n",
       "      <th>received_for_free</th>\n",
       "      <th>written_during_early_access</th>\n",
       "      <th>author.num_games_owned</th>\n",
       "      <th>author.num_reviews</th>\n",
       "      <th>author.playtime_forever</th>\n",
       "      <th>author.playtime_last_two_weeks</th>\n",
       "      <th>author.playtime_at_review</th>\n",
       "      <th>author.last_played</th>\n",
       "      <th>timestamp_dev_responded</th>\n",
       "      <th>developer_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228720</th>\n",
       "      <td>Beautiful art and music, fun gameplay and grea...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18400.0</td>\n",
       "      <td>1.624387e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228721</th>\n",
       "      <td>Hades has a lot going for it the soundtrack, v...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>189.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1.686744e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228723</th>\n",
       "      <td>perfect loop, beautiful art, fun weapons</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5790.0</td>\n",
       "      <td>5790.0</td>\n",
       "      <td>5790.0</td>\n",
       "      <td>1.686743e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228724</th>\n",
       "      <td>Combat : 10/10\\nReplayabilty : 10/10\\nStory + ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5399.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5399.0</td>\n",
       "      <td>1.670424e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228726</th>\n",
       "      <td>fun but u die alot LOL</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1.686744e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review voted_up  votes_up  \\\n",
       "228720  Beautiful art and music, fun gameplay and grea...     True       0.0   \n",
       "228721  Hades has a lot going for it the soundtrack, v...     True       0.0   \n",
       "228723           perfect loop, beautiful art, fun weapons     True       0.0   \n",
       "228724  Combat : 10/10\\nReplayabilty : 10/10\\nStory + ...     True       0.0   \n",
       "228726                             fun but u die alot LOL     True       0.0   \n",
       "\n",
       "        votes_funny  weighted_vote_score  comment_count steam_purchase  \\\n",
       "228720          0.0                  0.0            0.0           True   \n",
       "228721          0.0                  0.0            0.0           True   \n",
       "228723          0.0                  0.0            0.0           True   \n",
       "228724          0.0                  0.0            0.0           True   \n",
       "228726          0.0                  0.0            0.0          False   \n",
       "\n",
       "       received_for_free written_during_early_access  author.num_games_owned  \\\n",
       "228720             False                       False                     0.0   \n",
       "228721             False                       False                   189.0   \n",
       "228723             False                       False                     0.0   \n",
       "228724             False                       False                     0.0   \n",
       "228726             False                       False                     0.0   \n",
       "\n",
       "        author.num_reviews  author.playtime_forever  \\\n",
       "228720                 1.0                  18400.0   \n",
       "228721                44.0                   1011.0   \n",
       "228723                14.0                   5790.0   \n",
       "228724                 4.0                   5399.0   \n",
       "228726                 2.0                    330.0   \n",
       "\n",
       "        author.playtime_last_two_weeks  author.playtime_at_review  \\\n",
       "228720                             0.0                    18400.0   \n",
       "228721                          1011.0                     1011.0   \n",
       "228723                          5790.0                     5790.0   \n",
       "228724                             0.0                     5399.0   \n",
       "228726                           330.0                      270.0   \n",
       "\n",
       "        author.last_played  timestamp_dev_responded developer_response  \n",
       "228720        1.624387e+09                      NaN                NaN  \n",
       "228721        1.686744e+09                      NaN                NaN  \n",
       "228723        1.686743e+09                      NaN                NaN  \n",
       "228724        1.670424e+09                      NaN                NaN  \n",
       "228726        1.686744e+09                      NaN                NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     75508\n",
       "False     1236\n",
       "Name: voted_up, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['voted_up'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     76744.000000\n",
       "mean       5169.432190\n",
       "std        6119.080535\n",
       "min           5.000000\n",
       "25%        1859.000000\n",
       "50%        3914.000000\n",
       "75%        6598.000000\n",
       "max      272341.000000\n",
       "Name: author.playtime_forever, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author.playtime_forever'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    76744.000000\n",
       "mean        48.357474\n",
       "std         85.016701\n",
       "min          1.000000\n",
       "25%         11.000000\n",
       "50%         22.000000\n",
       "75%         50.000000\n",
       "max       1600.000000\n",
       "Name: review_length, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the length of each review (in words)\n",
    "df['review_length'] = df['review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Calculate the average length of reviews\n",
    "average_length = df['review_length'].mean()\n",
    "\n",
    "df['review_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#Setup lemmatizer\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [lemmatizer.lemmatize(w) for w in words if w.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Lemmatize the reviews\n",
    "df['review'] = df['review'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    76744.000000\n",
       "mean        48.357474\n",
       "std         85.016701\n",
       "min          1.000000\n",
       "25%         11.000000\n",
       "50%         22.000000\n",
       "75%         50.000000\n",
       "max       1600.000000\n",
       "Name: review_length, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode review length into categories based on specific ranges or thresholds\n",
    "df['review_length_category'] = pd.cut(df['review_length'], bins=[0, 8, 18, 44, np.inf], labels=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    21715\n",
       "1    21613\n",
       "2    21249\n",
       "0    12167\n",
       "Name: review_length_category, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_length_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['review_length_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average playtime\n",
    "average_playtime = df['author.playtime_forever'].mean()\n",
    "\n",
    "# Create new binary column\n",
    "df['above_average_playtime'] = np.where(df['author.playtime_forever'] > average_playtime, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    48192\n",
       "1    28552\n",
       "Name: above_average_playtime, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['above_average_playtime'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any non-string data in the review column to a string\n",
    "df['review'] = df['review'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vectorizer object to generate term frequency-inverse document frequency (tf-idf) vectors\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(df['review'])\n",
    "\n",
    "# Convert the TF-IDF matrix into a DataFrame\n",
    "df_tfidf = pd.DataFrame(df_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Reset index before concatenation\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_tfidf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate the TF-IDF features with your original DataFrame\n",
    "df = pd.concat([df, df_tfidf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the labels (positive or negative)\n",
    "y = df['voted_up'].map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>weighted_vote_score</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>steam_purchase</th>\n",
       "      <th>received_for_free</th>\n",
       "      <th>written_during_early_access</th>\n",
       "      <th>author.num_games_owned</th>\n",
       "      <th>...</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zag</th>\n",
       "      <th>zagreus</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beautiful art music , fun gameplay great voice...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hades lot going soundtrack , voice acting , ar...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>189.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perfect loop , beautiful art , fun weapon</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Combat : 10/10 Replayabilty : 10/10 Story + Wr...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fun u die alot LOL</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2520 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review voted_up  votes_up  \\\n",
       "0  Beautiful art music , fun gameplay great voice...     True       0.0   \n",
       "1  Hades lot going soundtrack , voice acting , ar...     True       0.0   \n",
       "2          perfect loop , beautiful art , fun weapon     True       0.0   \n",
       "3  Combat : 10/10 Replayabilty : 10/10 Story + Wr...     True       0.0   \n",
       "4                                 fun u die alot LOL     True       0.0   \n",
       "\n",
       "   votes_funny  weighted_vote_score  comment_count steam_purchase  \\\n",
       "0          0.0                  0.0            0.0           True   \n",
       "1          0.0                  0.0            0.0           True   \n",
       "2          0.0                  0.0            0.0           True   \n",
       "3          0.0                  0.0            0.0           True   \n",
       "4          0.0                  0.0            0.0          False   \n",
       "\n",
       "  received_for_free written_during_early_access  author.num_games_owned  ...  \\\n",
       "0             False                       False                     0.0  ...   \n",
       "1             False                       False                   189.0  ...   \n",
       "2             False                       False                     0.0  ...   \n",
       "3             False                       False                     0.0  ...   \n",
       "4             False                       False                     0.0  ...   \n",
       "\n",
       "    yo  you  young  youre  youtube  zag zagreus  zero zeus  zone  \n",
       "0  0.0  0.0    0.0    0.0      0.0  0.0     0.0   0.0  0.0   0.0  \n",
       "1  0.0  0.0    0.0    0.0      0.0  0.0     0.0   0.0  0.0   0.0  \n",
       "2  0.0  0.0    0.0    0.0      0.0  0.0     0.0   0.0  0.0   0.0  \n",
       "3  0.0  0.0    0.0    0.0      0.0  0.0     0.0   0.0  0.0   0.0  \n",
       "4  0.0  0.0    0.0    0.0      0.0  0.0     0.0   0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 2520 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['above_average_playtime'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split our Training and Test sets using only a portion of the data in order to save time\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_tfidf,\n",
    "    df['review_length_category'],\n",
    "    test_size=0.1,\n",
    "    train_size=0.4,\n",
    "    stratify=df['review_length_category'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RFC model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the training set results\n",
    "y_pred_rf_train = rf.predict(X_train)\n",
    "\n",
    "# Generate classification reports for the training data\n",
    "rf_report_train = classification_report(y_train, y_pred_rf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "xgb = XGBClassifier(random_state=42, verbosity=0)\n",
    "\n",
    "# Fit the Model\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict the training set results\n",
    "y_pred_xgb_train = xgb.predict(X_train)\n",
    "\n",
    "# Generate classification reports for the training data\n",
    "xgb_report_train = classification_report(y_train, y_pred_xgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      4867\n",
      "           1       1.00      0.99      1.00      8645\n",
      "           2       1.00      1.00      1.00      8499\n",
      "           3       1.00      1.00      1.00      8686\n",
      "\n",
      "    accuracy                           1.00     30697\n",
      "   macro avg       1.00      1.00      1.00     30697\n",
      "weighted avg       1.00      1.00      1.00     30697\n",
      "\n",
      "\n",
      "Training Data - XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      4867\n",
      "           1       0.82      0.84      0.83      8645\n",
      "           2       0.93      0.88      0.90      8499\n",
      "           3       0.99      0.98      0.98      8686\n",
      "\n",
      "    accuracy                           0.89     30697\n",
      "   macro avg       0.88      0.89      0.88     30697\n",
      "weighted avg       0.89      0.89      0.89     30697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification reports for the training data\n",
    "print(\"Training Data - Random Forest Classification Report:\")\n",
    "print(rf_report_train)\n",
    "print()\n",
    "print(\"Training Data - XGBoost Classification Report:\")\n",
    "print(xgb_report_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the parameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 300),\n",
    "    'max_depth': randint(3, 6),\n",
    "    'learning_rate': uniform(0.001, 0.1)\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb = XGBClassifier(random_state=42, verbosity=0)\n",
    "\n",
    "# Initialize RandomizedSearchCV with the XGBoost classifier and parameter distribution\n",
    "rand_search = RandomizedSearchCV(estimator=xgb, param_distributions=param_dist, n_iter=10, cv=3, random_state=42)\n",
    "\n",
    "# Fit the RandomizedSearchCV model\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters found by RandomizedSearchCV\n",
    "best_params = rand_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Use the best parameters to initialize a new XGBoost classifier\n",
    "best_xgb = XGBClassifier(random_state=42, verbosity=0, **best_params)\n",
    "\n",
    "# Fit the new XGBoost model with the best parameters\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict the training set results using the best model\n",
    "y_pred_xgb_train = best_xgb.predict(X_train)\n",
    "\n",
    "# Generate classification report for the training data\n",
    "xgb_report_train = classification_report(y_train, y_pred_xgb_train)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report (Training Data):\\n\", xgb_report_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a new DataFrame sentiments where each row corresponds to a review and each column corresponds to a theme. Each cell contains the average sentiment of the sentences in the corresponding review that mention the corresponding theme.\n",
    "\n",
    "Please note that this is a very simple example. In a more sophisticated sentiment analysis, you might use a more advanced model for sentiment analysis (such as a pre-trained model from HuggingFace's model hub), or use a more sophisticated method to identify sentences relevant to each theme. Also, error checking code is omitted for brevity, but you might want to add checks for things like division by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report (Test Data):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.72      0.69      1217\n",
      "           1       0.69      0.73      0.71      2161\n",
      "           2       0.82      0.76      0.79      2125\n",
      "           3       0.94      0.92      0.93      2172\n",
      "\n",
      "    accuracy                           0.79      7675\n",
      "   macro avg       0.78      0.78      0.78      7675\n",
      "weighted avg       0.79      0.79      0.79      7675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "xgb = XGBClassifier(random_state=42, verbosity=0)\n",
    "\n",
    "# Fit the model\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred_xgb_test = xgb.predict(X_test)\n",
    "\n",
    "# Generate classification report for the test data\n",
    "xgb_report_test = classification_report(y_test, y_pred_xgb_test)\n",
    "\n",
    "# Print the classification report for the test data\n",
    "print(\"XGBoost Classification Report (Test Data):\")\n",
    "print(xgb_report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify themes and synonyms\n",
    "themes = {\n",
    "    'music': ['sound', 'music', 'audio', 'instrument', 'soundtrack', 'voice acting', 'song', 'effect', 'atmosphere', 'orchestra'],\n",
    "    'story': ['story', 'plot', 'narrative', 'character', 'mission', 'quest', 'writing', 'dialogue', 'relationships', 'family', 'gods'],\n",
    "    'gameplay': ['gameplay', 'mechanics', 'controls', 'action', 'fight', 'attack', 'battle', 'weapon', 'moves', 'power', 'combat', 'upgrade'],\n",
    "    'visuals': ['visuals', 'graphics', 'art', 'images', 'color', 'artwork', 'animation', '2D', '3D', 'lighting']\n",
    "}\n",
    "\n",
    "# Create a new DataFrame for sentences\n",
    "sentences_df = pd.DataFrame(columns=['sentences'])\n",
    "\n",
    "# Tokenize the reviews into sentences and add them to the new DataFrame\n",
    "for review in df['review']:\n",
    "    sentences = nltk.sent_tokenize(str(review))\n",
    "    sentences_df = sentences_df.append({'sentences': sentences}, ignore_index=True)\n",
    "\n",
    "# Concatenate the sentences DataFrame with the original DataFrame\n",
    "df = pd.concat([df, sentences_df], axis=1)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sentiment = {}\n",
    "    if isinstance(row['sentences'], list):\n",
    "        sentences = [tuple(sentence) for sublist in row['sentences'] for sentence in sublist]  # Flatten and convert lists to tuples\n",
    "        sentences = ' '.join([' '.join(sentence) for sentence in sentences])  # Convert tuples to strings and join them\n",
    "        blob = TextBlob(sentences, analyzer=NaiveBayesAnalyzer())\n",
    "        for sentence in row['sentences']:\n",
    "            sentiment[tuple(sentence)] = blob.sentiment.classification  # Use tuples as keys\n",
    "    df.at[index, 'sentiment'] = str(sentiment)\n",
    "\n",
    "# Combine the sentiments DataFrame with the original reviews DataFrame\n",
    "df = pd.concat([df, df['sentiment']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Gensim Library to perform LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "decoding to str: need a bytes-like object, Series found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Apply preprocessing to each review\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_reviews\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(preprocess)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\learn-env\\Lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\learn-env\\Lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\learn-env\\Lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\learn-env\\Lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(v)\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m, in \u001b[0;36mpreprocess\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(text):\n\u001b[0;32m      2\u001b[0m     result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m simple_preprocess(text):\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m STOPWORDS \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(token) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m: \u001b[38;5;66;03m# ignore short and common words\u001b[39;00m\n\u001b[0;32m      5\u001b[0m             result\u001b[38;5;241m.\u001b[39mappend(WordNetLemmatizer()\u001b[38;5;241m.\u001b[39mlemmatize(token, pos\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;66;03m# get word roots\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\learn-env\\Lib\\site-packages\\gensim\\utils.py:311\u001b[0m, in \u001b[0;36msimple_preprocess\u001b[1;34m(doc, deacc, min_len, max_len)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimple_preprocess\u001b[39m(doc, deacc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, min_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m):\n\u001b[0;32m    289\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a document into a list of lowercase tokens, ignoring tokens that are too short or too long.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    Uses :func:`~gensim.utils.tokenize` internally.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m \n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    310\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 311\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokenize(doc, lower\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, deacc\u001b[38;5;241m=\u001b[39mdeacc, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m min_len \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(token) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_len \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    313\u001b[0m     ]\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\learn-env\\Lib\\site-packages\\gensim\\utils.py:262\u001b[0m, in \u001b[0;36mtokenize\u001b[1;34m(text, lowercase, deacc, encoding, errors, to_lower, lower)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iteratively yield tokens as unicode strings, optionally removing accent marks and lowercasing it.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \n\u001b[0;32m    230\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    259\u001b[0m \n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    261\u001b[0m lowercase \u001b[38;5;241m=\u001b[39m lowercase \u001b[38;5;129;01mor\u001b[39;00m to_lower \u001b[38;5;129;01mor\u001b[39;00m lower\n\u001b[1;32m--> 262\u001b[0m text \u001b[38;5;241m=\u001b[39m to_unicode(text, encoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lowercase:\n\u001b[0;32m    264\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\learn-env\\Lib\\site-packages\\gensim\\utils.py:365\u001b[0m, in \u001b[0;36many2unicode\u001b[1;34m(text, encoding, errors)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[1;32m--> 365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(text, encoding, errors\u001b[38;5;241m=\u001b[39merrors)\n",
      "\u001b[1;31mTypeError\u001b[0m: decoding to str: need a bytes-like object, Series found"
     ]
    }
   ],
   "source": [
    "# Define the preprocessing function\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in simple_preprocess(str(text)):\n",
    "        if token not in STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatizer.lemmatize(token, pos='v'))\n",
    "    return result\n",
    "\n",
    "# Apply preprocessing to each review\n",
    "df['processed_reviews'] = df['review'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing the reviews, you need to create a dictionary and a corpus that Gensim's LDA implementation can work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize each review string into a list of tokens\n",
    "tokenized_reviews = [review.split() for review in df['review']]\n",
    "\n",
    "# Create a dictionary representation of the documents\n",
    "dictionary = Dictionary(tokenized_reviews)\n",
    "\n",
    "# Filter out words that occur less than 20 documents or more than 50% of the documents\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
    "\n",
    "# Create Bag-of-words representation of the documents\n",
    "corpus = [dictionary.doc2bow(review) for review in tokenized_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m eval_every \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Don't evaluate model perplexity, takes too much time.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Make an index to word dictionary.\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m temp \u001b[38;5;241m=\u001b[39m dictionary[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# This is only to \"load\" the dictionary.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m id2word \u001b[38;5;241m=\u001b[39m dictionary\u001b[38;5;241m.\u001b[39mid2token\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m LdaModel(\n\u001b[0;32m     13\u001b[0m     corpus\u001b[38;5;241m=\u001b[39mcorpus,\n\u001b[0;32m     14\u001b[0m     id2word\u001b[38;5;241m=\u001b[39mid2word,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     eval_every\u001b[38;5;241m=\u001b[39meval_every\n\u001b[0;32m     22\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\learn-env\\Lib\\site-packages\\gensim\\corpora\\dictionary.py:107\u001b[0m, in \u001b[0;36mDictionary.__getitem__\u001b[1;34m(self, tokenid)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid2token) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken2id):\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# the word->id mapping has changed (presumably via add_documents);\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# recompute id->word accordingly\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid2token \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mrevdict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken2id)\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid2token[tokenid]\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Set training parameters\n",
    "num_topics = 4\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make an index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_topics = model.top_topics(corpus)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "for idx, (topic, coherence) in enumerate(top_topics):\n",
    "    print('Topic %d:' % idx)\n",
    "    print(' '.join([dictionary[int(word)] for word, _ in topic[:10]]), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
